---
title: "Analysing differential hydrogen deuterium exchange mass spectrometry data"
author:
- name: Oliver M. Crook
package: hdxstats
output:
  BiocStyle::html_document:
    toc_float: yes
abstract: "This vignette describes how to analyse a mass-spectrometry based  hydrogen
  deuterium exchange experiment, in particular we focus on empirical Bayes functional
  models and visualisations. \n"
vignette: |
  %\VignetteIndexEntry{Analysing differential hydrogen deuterium exchange mass spectrometry data}
  %\VignetteEngine{knitr::rmarkdown}
  %%\VignetteKeywords{Mass Spectrometry, MS, MSMS, Proteomics, Metabolomics, Infrastructure, Quantitative} %\VignetteEncoding{UTF-8}
---

```{r style, echo = FALSE, results = 'asis'}
BiocStyle::markdown()
```

```{r env, message = FALSE, warning = FALSE, echo = FALSE}
library("hdxstats")
library("dplyr")
library("ggplot2")
library("RColorBrewer")
library("tidyr")
library("pheatmap")
library("viridis")
library("patchwork")
```

# A well-defined HDX-MS experiment

This vignette describeds how to analyse time-resolved differential HDX-MS
experiments. The key elements are at least two conditions i.e. apo + antibody,
apo + small molecule or protein closed + protien open, etc. The experiment can
be replicated, though if there are sufficient time points analysed (>=3) then
occasionally signficant results can be obtained. The data provided should be
centroid-centric data. This package does not yet support analysis straight
from raw spectra. Typically this will be provided as a .csv from tools such as
dynamiX or HDExaminer.

# Main elements of the package

The package relies of Bioconductor infrastructure so that it integrates with
other data types and can benefit from advantages in other fields of mass-spectrometry.
There are package specific object, classes and methods but importantly there is
reuse of classes found in quantitative proteomics data, mainly the `QFeatures`
object which extends the `summarisedExperiment` class for mass spectrometry data.
The focus of this package is on testing and visualisation of the testing results.

# Data

We will begin with a structural variant experiment in which MHP and a structural
variant were mixed in different proportions. HDX-MS was performed on these samples
and we expect to see reproducible but subtle differences. We first load the data
from the package and it is .csv format.

```{r,}
MBPpath <- system.file("extdata", "MBP.csv", package = "hdxstats")
```

We can now read in the .csv file and have a quick look at the .csv.
```{r,}
MBP <- read.csv(MBPpath)
head(MBP) # have a look
length(unique(MBP$pep_sequence)) # peptide sequences
```

Let us have a quick visualisation of some the data so that we can see some of
the features

```{r,}
filter(MBP, pep_sequence == unique(MBP$pep_sequence[1]), pep_charge == 2) %>%
    ggplot(aes(x = hx_time, y = d, group = factor(replicate_cnt),
               color = factor(hx_sample,
                              unique(MBP$hx_sample)[c(7,5,1,2,3,4,6)]))) + 
    theme_classic() + geom_point(size = 2) + 
    scale_color_manual(values = brewer.pal(n = 7, name = "Set2")) + 
    labs(color = "experiment", x = "Deuterium Exposure", y = "Deuterium incoperation")
```
We can see that the units of the time dimension are in seconds and that
Deuterium incoperation has been normalized into Daltons.

# Parsing to an object of class QFeatures

Working from a .csv is likely to cause issues downstream. Indeed, we run
the risk of accidently changing the data or corrupting the file in some way.
Secondly, all .csvs will be formatted slightly different and so making extensible
tools for these files will be inefficient. Furthermore, working with a generic
class used in other mass-spectrometry fields can speed up analysis and adoption
of new methods. We will work the class `QFeatures` from the `QFeatures` class
as it is a powerful and scalable way to store quantitative mass-spectrometry data.

Firstly, the data is storted in long format rather than wide format. We first 
switch the data to wide format. 
```{r,}
MBP_wide <- pivot_wider(data.frame(MBP),
                        values_from = d,
                        names_from = c("hx_time", "replicate_cnt", "hx_sample"),
                        id_cols = c("pep_sequence", "pep_charge"))
head(MBP_wide)

```

We notice that there are many columns with `NA`s. The follow code chunk removes
these columns.
```{r,}
MBP_wide <- MBP_wide[, colSums(is.na(MBP_wide)) != nrow(MBP_wide)]
```

We also note that the colnames are not very informative. We are going to format
in a very specific way so that later functions can automatically infer the design
from the column names. We provide in the format X(time)rep(replicate)cond(condition)
```{r,}
colnames(MBP_wide)[-c(1,2)]

new.colnames <- gsub("0_", "0rep", paste0("X", colnames(MBP_wide)[-c(1,2)]))
new.colnames <- gsub("_", "cond", new.colnames)

# remove annoying % signs
new.colnames <- gsub("%", "", new.colnames)

# remove space (NULL could get confusing later and WT is clear)
new.colnames <- gsub(" .*", "", new.colnames)

new.colnames
```
We will now parse the data into an object of class `QFeatures`, we have provided
a function to assist with this in the package. If you want to do this yourself
use the `readQFeatures` function from the `QFeatures` package.
```{r,}
MBPqDF <- parseDeutData(object = DataFrame(MBP_wide),
                        design = new.colnames,
                        quantcol = 3:102)

```

# Heatmap visualisations of HDX data

To help us get used to the `QFeatures` we show how to generate a heatmap
of these data from this object:

```{r, fig.height = 16, fig.width = 20, fig.align = "center"}
pheatmap(t(assay(MBPqDF)),
         cluster_rows = FALSE, 
         cluster_cols = FALSE,
         color = brewer.pal(n = 9, name = "BuPu"),
         main = "Stuctural variant deuterium incoperation heatmap", 
         fontsize = 14,
         legend_breaks = c(0, 2, 4, 6, 8, 10, 12, max(assay(MBPqDF))),
         legend_labels = c("0", "2", "4", "6", "8","10", "12", "Incorporation"))
```


# Functional data analysis of HDX-MS data

The `hdxstats` package uses an empirical Bayes functional approach to analyse
the data. We explain this idea in steps so that we can get an idea of the approach.
First we fit the parametric model to the data. This will allow us to explore
the `HdxStatModel` class. 

```{r,}
res <- differentialUptakeKinetics(object = MBPqDF[,1:100], #provide a QFeature object
                                  feature = rownames(MBPqDF)[[1]][37], # which peptide to do we fit
                                  start = list(a = NULL, b = 0.0001,  d = NULL, p = 1)) # what are the starting parameter guesses
```
Here, we see the `HdxStatModel` class, and that a Functional Model was applied
to the data and a total of 7 models were fitted.
```{r,}
res
```
The `nullmodel` and `alternative` slots of an instance of `HdxStatModel` provide
the underlying fitted models. The `method` and `formula` slots provide vital 
information about what analysis was performed. The `vis` slot provides a `ggplot`
object so that we can visualise the functional fits.
```{r,}
res@vis
```

Since this is a ggplot object, we can customise in the usual grammatical ways.
```{r,}
res@vis + scale_color_manual(values = brewer.pal(n = 8, name = "Set2"))
```
A number of standard methods are available and can be applied to a `HdxStatModels`,
these extend the usual `base` stats methods. These include

1. `anova`: An analysis of variance
2. `logLik`: The log-likelihood of all the fitted models
3. `residuals`: The residuals for the fitted models
4. `vcov`: The variance-covariance matrix between parameters of the models
5. `likRatio`: The likelihood ratio between null and alternative models
6. `wilk`: Applies wilk's theorem to obtain a p-value from the liklihood ratio
7. `coef`: The fitted model coefficients
8. `deviance`: The deviance of the fitted models
9. `summary`: The statistical summary of the models.

```{r,}
anova(res)
logLik(res)
residuals(res)
vcov(res)
likRatio(res)
wilk(res)
coef(res)
deviance(res)
summary(res)

```
# Analysis of a typical HDX-MS experiment

We have seen the basic aspects of our functional modelling approach. We now
wish to roll out our method across all peptides in the experiment. The
`fitUptakeKinetics` function allows us to apply our modelling approach across
all the peptide in the experiment. We need to provide a `QFeatures` object 
and the features for which we are fitting the model. The design will be extracted
from the column names or you can provide a design yourself. The parameter 
initilisation should also be provided. Sometimes the model can't be fit on the
kinetics. This is either because there is not enough data or through lack of 
convergence. An error will be reported in these cases but this should not 
perturb the user. You may wish to try a few starting values if there 
excessive models that fail fitting. 

```{r,}
res <- fitUptakeKinetics(object = MBPqDF[,c(1:24)],
                         feature = rownames(MBPqDF[,c(1:24)])[[1]],
                         start = list(a = NULL, b = 0.001,  d = NULL, p = 1))

```
The code chunk above returns a class `HdxStatModels` indicating that a number
of models for peptide have been fit. This is simply a holder for a list
of `HdxStatModel` instances.
```{r,}
res
```

We can easily examine indivual fits by going to the underyling `HdxStatModel`
class:
```{r,}
res@statmodels[[1]]@vis + scale_color_manual(values = brewer.pal(n = 2, name = "Set2"))
```
We now wish to apply statistical analysis to these fitted curves. Our approach
is an empirical Bayes testing procedure, which borrows information across peptides
to stablise variance estimates. Here, we need to provide the original data
that was analysed and the `HdxStatModels` class. The following code chunk
returns an object of class `HdxStatRes`. This object tell us that statistical
analysis was performed using our Functional model.

```{r,}
out <- processFunctional(object = MBPqDF[,1:24], params = res)
out
```

The main slot of interest is the `results` slot which returns quantities of 
interest such as `p-values` and `fdr` corrected p-values because of multiple testing.
The following is the `DataFrame` of interest.
```{r,}
out@results
```

We can now examine the peptides for which the false discovery rate is less
than 0.05

```{r,}
which(out@results$ebayes.fdr < 0.05)
```
Let us visualise some of these examples:
```{r,}
res@statmodels[[42]]@vis + res@statmodels[[45]]@vis

```
As we can see our model has picked up some subtle differences, we can further
visualise these using a forest plot. We can see the the functions are very similar
as the parameters are almost identical `(a,b,p,d)`. However, we can see that
the deuterium differences are lower in 10% structural variant condition.

```{r,}
fp <- forestPlot(params = res@statmodels[[42]])

```
We can produce a table to actual numbers. We see that at all 4 timepoints
the deuterium difference is negative, though the confidence intervals overlap
with 0. Our functional approach is picking up this small but reproducible difference.
```{r,}
knitr::kable(fp$data)
```

Let's us now have a look a situation where the changes are more dramatic.

```{r,}
res_wt <- fitUptakeKinetics(object = MBPqDF[, c(61:100)],
                            feature = rownames(MBPqDF[, c(61:100)])[[1]],
                            start = list(a = NULL, b = 0.001,  d = NULL, p = 1))

```
```{r,}
out_wt <- processFunctional(object = MBPqDF[, c(61:100)], params = res_wt)
```

We can visualise some of the result and generate plots.
```{r, fig.height = 16, fig.width = 20, fig.align = "center"}
res_wt@statmodels[[27]]@vis/res_wt@statmodels[[28]]@vis + plot_layout(guides = "collect")|(forestPlot(params = res_wt@statmodels[[27]], condition = c("WT", "W169G"))/forestPlot(params = res_wt@statmodels[[28]], condition = c("WT", "W169G")) + plot_layout(guides = "collect")) + 
    plot_annotation(tag_levels = 'a') +  plot_layout(widths = c(1, 1))
```




